
<머리말>


드디어 데이터 분석의 4단계 절차인 데이터 모델링과 그 평가에 대해 배운다. 지금까지 조사목적에 따라 데이터를 수집하고 분류하며 샘플링 및 사전 점검, 적합한 데이터를 모집단으로 추출한 것은 합리적인 데이터 모델링을 하기 위해서였다. 개인적으로 머신러닝의 가장 근본이 되는 파트라고 생각하기 때문에 수업 내용이 기대된다.


<사전 지식>

1. 데이터 모델링이란
: 데이터 모텔링이란 기업이나 조직의 정보를 효과적으로 관리하고 활용하기 위해, 데이터의 구조와 관계를 정의하고 표현하는과정을 말한다. 이는 데이터베이스를 설계하기 위한 작업이기도 하다(구글). 이는 모델링을 위한 데이터 사전 준비, 모델 선정, 모델링 및 성능 비교, 모델 평가의 과정으로 진행된다.

2. 인코딩이란
: 어떤 정보의 형태나 형식을 다른 형태로 변환하는 처리 혹은 방식으로, 주로 데이터의 저장 공간을 절약하거나 정보의 처리속도를 향상시키거나 컴퓨터가 이해할 수 있는 디지털 형태로 만들기 위해 사용된다.(구글)


<본론>

1.모델링을 위한 데이터 사전 준비

(1) 모델이 이해할 수 있는 데이터의 형태로 가공
: 모델은 숫자로 이루어진 형태의 Data만 인식 가능(문자형 변수 인코딩 필요)
: 모델링을 수행하기 위해 Feature와 예측하고자하는 값인 Y로 데이터를 나눔
: 학습과 예측을 위한 Train/Test set 분할

(2) 대표적인 인코딩 방법
-One-hot encoding: 범주형(Categorical) 변수의 유형 만큼 새로운 Feature을 생성하고, 1과 0으로 표현
-Label encoding: 범주형 변수의 unique한 값만큼 증가하는 숫자를 부여

(3) One-hot encoding
: 범주형 데이터의 unique한 값이 증가하면 증가할 수록 변수의 차원이 늘어나는 효과
: 예측 성능의 저하
: 범주형 변수의 unique한 수준을 축소하고 사용하기를 권장

(4) Label encoding
: unique하고 증가하는 숫자값으로 변환되어 숫자의 ordinal한 특성이 반영되어 의도하지 않은 관계성이 생김
: 숫자값을 가중치로 잘못 인식하여 값에 왜곡이 생김
: 예측 성능의 저하
: 선형회귀와 같은 ML 알고리즘에는 적용하지 않음
: Tree 계열의 알고리즘은 숫자의 ordinal한 특성을 반영하지 않으므로 진행 가능

2. Model Selection
: 대표적인 알고리즘에 대해서는 모두 Test하는 것이 유리
: 분석하고자하는 데이터의 특성이 모두 다르므로 완벽한 알고리즘은 없음
: 최신 개발되고 복잡한 알고리즘이 가장 성능이 좋은 것은 아님
: 동일한 작동원리의 알고리즘을 사용하기보다는, 다른 작동원리를 가지고 있는 다양한 알고리즘을 선정

-regression
: 선형회귀 모델(Ridge, Lasso, Elastic Net)
: 비선형회귀 모델(polyncmial, log모형)
: Tree 계열 Regression 모델(bagging 앙상블, boosting 앙상블)

-classification
: 로지스틱 모델(Logistic regression)
: Tree 계열 Regression 모델(bagging 앙상블, boosting 앙상블)

3. 모델링 및 성능 비교

(1) Model 학습
: Model Selection 단계에서 선정한 모델들을 학습하고 성능을 기록
: 동일한 Data set, 동일한 환경에서 동일한 비교 지표로 성능을 비교

(2) 성능평가
-Regression
: MAE(Mean Absolute Errors) = 평균절대오차, 단위 자체가 기존 데이터와 동일
: MSE(Mean Squared Errors) = 평균제곱오차, 제곱으로 인해 원래의 오차보다 민감하게 오차가 표현됨, 오차의 민감도를 높이는 효과
: RMSE(Root Mean Square of Errors) = MSE에 Root를 씌어 단위를 맞춤
: R2(R Squared Score) = 결정계수, 관측값의 분산대비 예측값의 분산을 비교하여 모델의 정확도 성능을 측정, 0~1까지 표현
-Classfication
: Precision(정밀도) = True라고 예측한 것들 중에 실제 True인 것의 비율
: Recall(재현율, sensitivity) = 실제 True인 것 중에 모델이 True라고 예측한 것의 비율
: F1-score(조회평균) = precision과 recall의 조회평균, 데이터의 Label이 불균형일 때 모델의 성능을 객관적으로 평가할 수 있음
: AUC, AURCC(Area Under RCC Curve): X축(FPR, False Positive Rate), False인데 True라고 잘 못 예측한 비율/ Y축(Recall)

(3) Model 학습
-Model 1 : Logistic Regression
-Model 2: Random Forest
-Model 3: LightGBM

4. Model Evaluation
(1) 전체 모델 성능 평가
: Hyper parameter turning 전 전체 모델 성능 비교

(2) 과적합(Over-fitting)
: train data를 활용하여 학습된 모델의 성능과 test data를 예측한 성능의 Gap이 큰 것
: train data에 너무 치중되어 학습한 결과로 발생함
: 과적합이 발생하면, Robust한 모델이 될 수 없고, 모델 운영시 일정한 성능을 유지할 확률이 낮음

(3) 과적합 해결방법
: 다양한 방법들이 존재하지만, 현업에서는 하이퍼파라미터 조절을 통한 규제로 과적합을 방지
: Tree model을 예시로 max_depth(분기의 길이) 값을 작은 값으로 설정하여 모델이 학습 데이터를 덜 학습하게 만듬
: 더 Robust한 모델을 만들기 위해서 Train/Test data를 활용하여 하이퍼파라미터를 튜닝하고, Validation set으로 최종 성능평가를 진행함
: Train/Validation/Test의 성능 차이의 Gap을 최소화하면서 성능을 향상시킬 수 있는 튜닝을 진행


<마무리>

데이터 분석 과정 중 데이터 수집 등의 초기 단계에서 데이터 분석가는 데이터로부터 합리적인 결과를 얻기 위해 많은 시간과 비용을 투자했을 것이다. 그렇기에 마무리 단계인 데이터 결과 해석 과정에서 분석가의 무지와 실수로 인해 잘못된 정보를 얻어 실무에 적용하게 된다면 이전까지 분석에 소요된 시간과 비용 뿐만 아니라 이후 실무에서 발생하는 손실까지 그 책임을 물어야 할 것이다. 수업의 마무리에서 강사님은 데이터 분석 과정에 소요되는 시간이 신입의 경우 2달, 경력직의 경우 1달 반 정도 소모된다고 얘기해주셨다. 적지 않은 시간이 소요되는 만큼 데이터분석에 대한 이론을 더 열심히 공부해야 할 필요를 느꼈다.

출처: 패스트캠퍼스 온라인 수업, 구글
#패스트캠퍼스 #패스트캠퍼스AI부트캠프 #업스테이지패스트캠퍼스 #UpstageAILab #국비지원 #패스트캠퍼스업스테이지에이아이랩 #패스트캠퍼스업스테이지부트캠프
﻿

# 1. 머리말

대규모 언어 모델(LLM)은 방대한 데이터를 이용하여 사전학습이 되었지만, 그 지식은 모두 파라미터 내부(parametric memory)에 암묵적으로 저장된다. 이는 모델이 학습 시점까지의 데이터를 통계적으로 요약해서 보유한다는 의미로, 외부 지식을 이용한다는 것과는 다른 개념이다.

이 구조는 세 가지의 대표적인 문제를 발생시킨다.

첫 번째 문제는 **지식의 최신성 문제**이다. 학습 이후에 새로 발생한 사건이나 변경된 정보는 모델이 반영할 수 없다.  
두 번째 문제는 **도메인 특화 지식의 한계**이다. 특정 조직의 내부 문서, 사내 규정, 전문 매뉴얼 등은 일반적인 사전학습 데이터에 포함되지 않으므로, 전문적인 지식을 요하는 경우 LLM은 이를 완벽하게 다룰 수 없다.  
세 번째 문제는 **근거 기반 응답의 부재**이다. 모델은 답변을 생성할 수는 있지만, 그 답변의 근거가 무엇인지에 대해서는 구조적으로 설명하지 못한다.

이 문제들은 모델 크기를 키운다고 해서 해결되는 문제가 아니므로, 성능 문제가 아니라 **지식 접근 방식의 한계**로서 다루어야 한다.

---

# 2. Hallucination의 구조적 발생 이유

LLM은 본질적으로 다음 확률을 최대화하는 모델이다.


이 확률은 주어진 `x`에 대해 가장 그럴듯해 보이는 출력 `y`를 생성할 뿐, 그 출력값이 사실인지의 여부는 판단하지 않는다. 모델은 기본적으로 입력에 충분한 정보가 없더라도 *모르겠다*는 답변을 생성하지 않으려 하기에, 확률적으로 자연스러운 답변을 대신 생성한다.

Hallucination이란 이러한 모델의 태도로 인해 발생하는 현상이다. 그렇기에 유의해야 할 점은 Hallucination이 단순 오류나 버그가 아니라, **확률적 언어 모델의 자연스러운 결과**라는 점이다. 이를 완전히 제거하려는 시도는 불가능하며, 대신 엔지니어는 **발생 조건을 통제하고 영향 범위를 줄이는 방향**으로 접근해야 한다.

---

# 3. 해결 방법으로서의 Fine-tuning

Hallucination이나 LLM의 지식적 한계를 마주했을 때, 초기 엔지니어들은 이를 **Fine-tuning**으로 해결하려 했다. 실제로 특정 도메인 데이터로 모델을 추가 학습하면 성능이 개선되는 경우도 있었으나, 이 접근은 구조적인 한계를 가진다.

- 새로운 정보가 생길 때마다 재학습이 필요하다.  
- 데이터 수집 및 정제 비용이 크다.  
- 모델 파라미터가 태스크에 과도하게 특화될 수 있다.  
- 근거 추적이나 출처 제시는 여전히 어렵다.  

즉, Fine-tuning은 지식을 **다시 파라미터 안에 집어넣는 방식**일 뿐, 지식 접근 구조 자체를 바꾸지는 않는다. 이 방식은 확장성과 운영 측면에서 빠르게 한계에 도달한다.

---

# 4. RAG의 출현

RAG(Retrieval-Augmented Generation)는 이러한 문제를 다른 방향에서 해결하고자 한다. 모델이 답을 생성하기 전에 **부족한 정보를 외부에서 가져오게 하자**는 접근이다.

즉, 지식을 파라미터 내부에 모두 저장하려 하지 않고, 외부 문서 저장소를 별도로 두고 필요할 때 검색함으로써 정확성과 신뢰성을 높이고자 한 것이다. 이는 모델의 역할을 단순한 기억 저장소에서, **지식을 활용해 추론하는 존재**로 변화시켰다.

확률 관점에서 보면 RAG는 다음과 같은 변화를 만든다.

- P(y | x, d₁, d₂, ..., dₙ)


여기서 `dₙ`은 검색을 통해 얻은 문서 정보(텍스트, 문단 등)이다. 모델은 더 이상 부족한 입력값에만 의존하지 않고, **명시적인 근거를 조건으로 답변을 생성**할 수 있게 된다.

---

# 5. RAG로 인한 변화

RAG는 단순히 출력값의 정답률을 높이는 것이 아니라, **모델의 실패 양상을 바꾸는 것**을 목적으로 한다.

검색이 실패하면 답변이 부정확해질 수는 있지만, 적어도 실패 원인이 **검색 단계로 국소화**된다. 이는 모델의 디버깅과 개선이 가능해졌다는 뜻이다.

LLM 단독 시스템에서는 Hallucination이 모델 내부에서 발생하여 그 원인을 추적하기 어렵다. 반면 RAG 시스템에서는 다음과 같은 단계별 분석이 가능하다.

- 검색 결과 문제  
- 문서 선택 오류  
- 프롬프트 구성 문제  

이처럼 RAG는 원인 추적이 가능하다는 점에서 **운영 가능한 구조**로 평가된다.

---

# 6. 마무리

RAG는 다음과 같은 설계 선택을 포함한다.

- 어떤 정보를 파라미터 밖으로 둘 것인가  
- 언제 검색을 트리거할 것인가  
- 검색 실패를 어떻게 처리할 것인가  
- 생성 결과를 어떻게 검증할 것인가  

즉, RAG란 시스템의 경계를 재정의하는 방식이지, LLM의 한계를 가리는 임시방편이 아니다. 이는 LLM을 실제 지식과 연결하기 위한 **구조적인 방법**이다.

RAG는 모델의 성능 자체를 높이는 것이 아니라, **지식 접근 방식을 분리함으로써 정확성과 신뢰성을 확보**한다.

---

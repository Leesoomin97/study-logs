# 1. 머리글

자연어 처리(Natural Language Processing, NLP)는 인간이 사용하는 언어를 컴퓨터가 이해하고, 처리하며, 생성할 수 있도록 만드는 연구 분야이다. 텍스트와 음성을 포함한 자연어 데이터를 대상으로 하며, 정보 추출, 분류, 요약, 생성 등 다양한 문제를 다룬다.

최근 NLP는 딥러닝과 대규모 언어 모델의 발전으로 빠르게 성장했지만, 여전히 언어 고유의 복잡성으로 인해 해결해야 할 난제가 많다. 본 글에서는 NLP의 정의와 범위를 정리하고, 자연어가 가지는 구조적 특성이 왜 NLP를 어려운 문제로 만드는지 살펴본다.

---

# 2. 자연어 처리의 정의와 범위

자연어 처리는 크게 다음 두 영역으로 나눌 수 있다.

**자연어 이해(NLU, Natural Language Understanding)**  
: 문장의 의미를 이해하고, 정보나 의도를 추출하는 문제  
(예시: 문서 분류, 감정 분석, 개체명 인식, 질의응답)

**자연어 생성(NLG, Natural Language Generation)**  
: 의미 있는 문장을 생성하는 문제  
(예시: 문서 요약, 기계 번역, 대화 시스템, 텍스트 생성)

대부분의 실제 NLP 시스템은 NLU와 NLG 요소를 함께 포함하며, 최근에는 이 둘의 경계가 점점 흐려지고 있다.

---

# 3. 자연어 처리가 다루는 대표적인 문제 유형

NLP task는 처리 단위와 목적에 따라 다음과 같이 구분할 수 있다.

- **문서 단위**  
  - 문서 분류(Document Classification)  
  - 문서 요약(Summarization)

- **문장 단위**  
  - 감정 분석(Sentiment Analysis)  
  - 문장 유사도(Sentence Similarity)  
  - 자연어 추론(NLI)

- **토큰 단위**  
  - 개체명 인식(NER)  
  - 품사 태깅(POS Tagging)

- **생성 중심**  
  - 기계 번역(Machine Translation)  
  - 대화 생성(Dialogue Generation)

이러한 태스크들은 모두 자연어를 어떻게 표현하고, 어떻게 모델이 이해하게 할 것인가라는 공통 문제를 가진다.

---

# 4. 자연어의 언어적 특성

자연어는 구조적으로 다음과 같은 특성을 가진다.

## (1) 이산적이고 불규칙적인 표현

언어는 연속적인 신호가 아니라 이산적인 기호의 조합으로 구성된다. 동일한 의미도 다양한 표현으로 나타날 수 있으며, 표현의 규칙성이 낮다.

- 같은 의미, 다른 표현  
- 같은 표현, 다른 의미(다의어)

이로 인해 단순 규칙 기반 접근은 일반화에 한계를 가진다.

## (2) 문맥 의존성(Context Dependency)

자연어의 의미는 단어 자체보다 문맥에 의해 결정된다.

- 단어 수준에서의 의미 변화  
- 문장 내 위치, 주변 단어에 따른 의미 차이  
- 문장 간 맥락에 따른 해석 변화  

이 특성 때문에 NLP 모델은 단순히 단어를 독립적으로 처리할 수 없으며, 문맥 정보를 함께 고려해야 한다.

## (3) 구조적 계층성(Hierachical Structure)

자연어는 계층적 구조를 가진다.

- 문장 → 토큰 → 구 → 문장 → 문서

이 구조는 선형적인 데이터 처리 방식과 충돌하며, 순서 정보와 장거리 의존성(Long-range Dependency) 문제가 발생한다.

---

# 5. 자연어 처리가 어려운 이유

자연어 처리가 어려운 이유는 단순히 데이터가 텍스트이기 때문이 아니라, 다음과 같은 특성들이 동시에 존재하기 때문이다.

- 명확한 규칙으로 정의하기 어려움  
- 의미가 문맥에 따라 유동적  
- 구조적 계층성과 순서 의존성 공존  
- 언어, 도메인, 사용자에 따른 표현 차이  

이러한 문제를 해결하기 위해 NLP는 규칙 기반 → 통계 기반 → 딥러닝 기반 접근으로 발전해 왔다.

---

# 6. NLP 발전의 흐름

자연어 처리의 발전은 다음과 같이 요약할 수 있다.

**① 규칙 기반 NLP**  
- 사람이 정의한 문법과 규칙 사용  
- 확장성과 일반화에 한계  

**② 통계 기반 NLP**  
- 확률 모델과 피처 엔지니어링  
- 데이터 의존성 증가  

**③ 딥러닝 기반 NLP**  
- 표현 학습(Representation Learning)  
- End-to-End 학습  
- 대규모 사전학습 모델 등장  

이 시리즈에서는 이 흐름을 따라가며, 각 단계에서 사용된 핵심 아이디어와 모델 구조를 정리한다.

---

# 7. 마무리

이번 글에서는 자연어 처리와 문제 정의와 언어적 특성을 중심으로 NLP의 큰 그림을 살펴보았다. 다음 글에서는 NLP 파이프라인의 출발점인 텍스트 전처리와 토큰화, 그리고 서브 워드 단위 표현이 등장한 배경을 다룰 예정이다.


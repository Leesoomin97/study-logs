# 1. 머리글

LLM을 실무에서 적용하면 기존 머신러닝 평가 방식에서 사용하던 평가 방식이 한계점이 있다는 사실을 빠르게 알아차릴 수 있다. 전통적인 NLP에서는 정답 레이블과 평가 지표가 명확했지만, LLM 시스템에서는 정답이 무엇인지 자체가 상황에 따라 달라진다. 이는 같은 질문이라도 사용자의 목적, 맥락, 제약 조건에 따라 합리적인 출력이 여러 개 존재하기 때문일 것이다.

결과적으로 LLM 평가는 더 이상 모델의 성능 측정 문제가 아니라, **불확실한 시스템의 품질을 어떻게 관리할 것인가의 문제**로 전환된다.

---

# 2. 기존 NLP 지표의 한계점

BLEU, ROUGE, Accuracy와 같은 기존 지표들은 출력된 텍스트가 정답과 얼마나 유사한지를 측정하는 지표였다. 그러나 RAG, Tool Use, Agent 구조가 결합된 LLM 시스템에서는 이러한 접근에서 그 유의미성을 찾기가 어렵다.

LLM 시스템의 품질은 출력된 문자열이 아니라 **문제 해결 과정 전체**에 의해 결정되기 때문이다.  
예를 들어 다음과 같은 요소들은 텍스트 자체가 아니라 **의사결정 과정**을 평가하는 것이다.

- 검색을 수행했는가  
- 툴을 적절히 호출했는가  
- 불확실한 상황에서 과도한 확신을 보이지 않았는가  

이는 기존 지표로 포착하기 어려운 특징이다.

의사결정 과정 전체를 살핌으로써 LLM 평가는 **신뢰성(Reliability)**을 측정한다.  
결과적으로 LLM 평가란 모델의 언어 능력을 재는 것이 아니라, **시스템 설계가 의도대로 작동했는지 확인하는 과정**이다.

---

# 3. 평가 대상의 변화

LLM 평가의 핵심 전환점은 평가 대상을 **출력 텍스트(output)**가 아닌 **시스템 행동(behavior)**으로 이동시키는 것이다.

시스템이 평가해야 할 핵심 질문은 다음과 같다.

- 사용자 의도를 올바르게 해석했는가  
- 외부 지식이 필요한 경우 검색을 수행했는가  
- 답변이 검색 결과 또는 툴 출력에 기반하고 있는가  
- 불확실한 상황에서 적절한 수준의 확신을 유지했는가  

즉, 평가는 *무엇을 말했는지*가 아니라, **어떤 의사결정을 거쳐 최종 결론에 도달했는지**를 보는 일이다.

---

# 4. LLM 시스템의 핵심 평가 축

LLM 시스템에서 실질적으로 사용되는 핵심 평가 축은 다음 세 가지로 정리할 수 있다.

| 평가 축 | 정의 | 핵심 질문 |
|------|------|----------|
| Faithfulness | 답변이 제공된 근거와 일치하는가 | 근거 없는 생성이 발생했는가 |
| Helpfulness | 사용자 목적을 충족했는가 | 다음 행동에 충분한 정보를 주는가 |
| Calibration | 모델의 확신 수준이 적절한가 | 모르는 상황에서 과신하지 않는가 |

### Faithfulness
RAG 기반 시스템에서 가장 중요한 축이다.  
검색된 문서에 없는 내용을 답변에 포함하는 경우는 가장 심각한 문제로 간주된다.

### Helpfulness
단순히 사실이 맞는지를 넘어, **사용자가 다음 행동을 취할 수 있을 만큼 충분한 정보를 제공했는지**가 핵심이다.  
이 과정에서는 안전성(Harmlessness)과의 균형도 함께 고려된다.

### Calibration
LLM 시스템에서 가장 위험한 상황은 *틀린 답변*이 아니라, **틀린 답변을 매우 당당하게 말하는 경우**이다.  
모르는 상황에서 명확히 한계를 드러내는 것은 신뢰성의 핵심 요소이며, Hallucination 위험 관리의 핵심이다.

---

# 5. 자동 평가와 인간 평가의 비교

LLM 평가를 전면 자동화하는 것도, 전면 수동으로 수행하는 것도 현실적이지 않다.  
따라서 실제 운영 환경에서는 두 방식을 명확히 분리해 사용한다.

| 구분 | 역할 |
|----|-----|
| 자동 평가 | 규칙 위반 탐지, 포맷 검사, 검색/툴 사용 여부 확인 |
| 인간 평가 | 의미 적합성, 신뢰성 판단, 도움 정도 평가 |

자동 평가 지표는 **최종 품질 판단의 결정자**가 아니라, 문제를 조기에 탐지하는 **필터 역할**을 수행한다.

---

# 6. 운영 단계에서 LLM 시스템의 실패 유형과 핵심 전략

실제 서비스 환경에서 발생하는 문제는 대부분 **모델 성능과 직접적인 관련이 없다**.  
오히려 다음과 같은 **시스템 레벨 이슈**가 더 자주 발생한다.

- 검색 실패 시 fallback 전략 부재  
- Tool 호출 오류에 대한 예외 처리 미흡  
- Agent 루프의 비정상 종료 또는 무한 반복  
- 프롬프트 변경 후 성능 회귀(regression) 발생  

이러한 문제는 모델을 교체해도 해결되지 않으며, **제어 로직·모니터링·실패 관리 전략**이 핵심 대응 수단이 된다.

LLM 운영의 핵심 전략은 다음 세 가지로 요약된다.

1. 실패를 예외가 아니라 **전제로 설계할 것**  
2. 모델 출력을 신뢰하지 말고 **검증 가능한 대상으로 취급할 것**  
3. 모델 성능이 아니라 **시스템 동작을 모니터링할 것**  

---

# 7. 마무리

LLM 평가와 운영은 단순히 성능 점수를 높이는 문제가 아니다. 이는 **불확실한 시스템을 어떻게 통제 가능한 상태로 유지할 것인가**를 다루는 문제이다.

출력의 정확성뿐 아니라, 그 전체 과정을 이루는 **일관성, 예측 가능성, 실패 관리 능력**이 함께 중요해진다. 이러한 기준이 갖추어질 때, LLM은 연구용 모델을 넘어 **실제 실무에서 운영되는 서비스의 핵심 컴포넌트**로 기능할 수 있다.

---
